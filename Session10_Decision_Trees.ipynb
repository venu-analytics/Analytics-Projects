{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session10_Decision Trees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venu-analytics/Analytics-Projects/blob/main/Session10_Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEI8ov5a2tgW"
      },
      "source": [
        "## Initialisation and Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jywske-q0VZt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "00a353c0-da11-4269-ca09-fb10831b70c6"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.2.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu artful-security InRelease [83.2 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu artful InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful-updates InRelease [88.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu artful-backports InRelease [74.6 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu artful-security/universe Sources [21.5 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu artful-security/universe amd64 Packages [84.3 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu artful-security/main amd64 Packages [237 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu artful-updates/universe Sources [46.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu artful-updates/universe amd64 Packages [150 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 Packages [365 kB]\n",
            "Fetched 1,150 kB in 1s (819 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI3mW5Lx15ps"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.2.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEyS_PW12DmR"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhhjKzhX2EKZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "97a2ed9b-cf08-4ee7-add1-11b0e8e07865"
      },
      "source": [
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://172.17.0.2:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLmaX6Fl2HMV"
      },
      "source": [
        "import urllib\n",
        "f = urllib.request.urlretrieve (\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\", \"kddcup.data_10_percent.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ7xDYQ-2ZWT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b72e955-a08d-466b-b2b4-f24a274a8d6a"
      },
      "source": [
        "data_file = \"./kddcup.data_10_percent.gz\"\n",
        "raw_data = sc.textFile(data_file)\n",
        "\n",
        "print (\"Train data size is {}\".format(raw_data.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data size is 494021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d7H2HL52e97"
      },
      "source": [
        "ft = urllib.request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz\", \"corrected.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1u3dxIh2mFs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26b33e8d-40d7-4589-bce8-4b0a6f8f3036"
      },
      "source": [
        "test_data_file = \"./corrected.gz\"\n",
        "test_raw_data = sc.textFile(test_data_file)\n",
        "\n",
        "print (\"Test data size is {}\".format(test_raw_data.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data size is 311029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu8q9H814uPI"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aoHWEry2qST"
      },
      "source": [
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from numpy import array\n",
        "\n",
        "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
        "test_csv_data = test_raw_data.map(lambda x: x.split(\",\"))\n",
        "\n",
        "protocols = csv_data.map(lambda x: x[1]).distinct().collect()\n",
        "services = csv_data.map(lambda x: x[2]).distinct().collect()\n",
        "flags = csv_data.map(lambda x: x[3]).distinct().collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMmHEnQRQAov"
      },
      "source": [
        "def create_labeled_point(line_split):\n",
        "    # leave_out = [41]\n",
        "    clean_line_split = line_split[0:41]\n",
        "    \n",
        "    # convert protocol to numeric categorical variable\n",
        "    try: \n",
        "        clean_line_split[1] = protocols.index(clean_line_split[1])\n",
        "    except:\n",
        "        clean_line_split[1] = len(protocols)\n",
        "        \n",
        "    # convert service to numeric categorical variable\n",
        "    try:\n",
        "        clean_line_split[2] = services.index(clean_line_split[2])\n",
        "    except:\n",
        "        clean_line_split[2] = len(services)\n",
        "    \n",
        "    # convert flag to numeric categorical variable\n",
        "    try:\n",
        "        clean_line_split[3] = flags.index(clean_line_split[3])\n",
        "    except:\n",
        "        clean_line_split[3] = len(flags)\n",
        "    \n",
        "    # convert label to binary label\n",
        "    attack = 1.0\n",
        "    if line_split[41]=='normal.':\n",
        "        attack = 0.0\n",
        "        \n",
        "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wk8ySEzRcO1"
      },
      "source": [
        "training_data = csv_data.map(create_labeled_point)\n",
        "test_data = test_csv_data.map(create_labeled_point)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1xdZJSOSvKV"
      },
      "source": [
        "## Training a classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "934tBiSURfUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a79e475-3ac2-440c-c7b3-00755e3c3fc4"
      },
      "source": [
        "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
        "from time import time\n",
        "\n",
        "# Build the model\n",
        "t0 = time()\n",
        "tree_model = DecisionTree.trainClassifier(training_data, numClasses=2, \n",
        "                                          categoricalFeaturesInfo={1: len(protocols), 2: len(services), 3: len(flags)},\n",
        "                                          impurity='gini', maxDepth=4, maxBins=100)\n",
        "tt = time() - t0\n",
        "\n",
        "print (\"Classifier trained in \",round(tt,3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier trained in  17.969  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1wLMH7rS7Xb"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6di-3Ks3Rh7p"
      },
      "source": [
        "predictions = tree_model.predict(test_data.map(lambda p: p.features))\n",
        "labels_and_preds = test_data.map(lambda p: p.label).zip(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvj-kl04Rz3_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "577c5dd7-570d-4ec0-e06a-c0702c5ff379"
      },
      "source": [
        "t0 = time()\n",
        "test_accuracy = labels_and_preds.filter(lambda x: x[0] == x[1]).count() / float(test_data.count())\n",
        "tt = time() - t0\n",
        "\n",
        "print (\"Prediction made in \",round(tt,3),\" seconds. Test accuracy is\",round(test_accuracy,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction made in  17.571  seconds. Test accuracy is 0.9186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNxbIhZtTGcx"
      },
      "source": [
        "## Interpreting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6yk7jekR0k0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "88e08225-2bfc-45a8-90cf-f3c8f1e6ad4a"
      },
      "source": [
        "print (\"Learned classification tree model:\")\n",
        "print (tree_model.toDebugString())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learned classification tree model:\n",
            "DecisionTreeModel classifier of depth 4 with 27 nodes\n",
            "  If (feature 22 <= 68.0)\n",
            "   If (feature 25 <= 0.67)\n",
            "    If (feature 9 <= 0.0)\n",
            "     If (feature 36 <= 0.43)\n",
            "      Predict: 0.0\n",
            "     Else (feature 36 > 0.43)\n",
            "      Predict: 1.0\n",
            "    Else (feature 9 > 0.0)\n",
            "     If (feature 4 <= 1091.0)\n",
            "      Predict: 0.0\n",
            "     Else (feature 4 > 1091.0)\n",
            "      Predict: 1.0\n",
            "   Else (feature 25 > 0.67)\n",
            "    If (feature 3 in {0.0,5.0,1.0,2.0,3.0})\n",
            "     If (feature 2 in {0.0,5.0,10.0,1.0,6.0,2.0,30.0,4.0,15.0})\n",
            "      Predict: 0.0\n",
            "     Else (feature 2 not in {0.0,5.0,10.0,1.0,6.0,2.0,30.0,4.0,15.0})\n",
            "      Predict: 1.0\n",
            "    Else (feature 3 not in {0.0,5.0,1.0,2.0,3.0})\n",
            "     If (feature 38 <= 0.06)\n",
            "      Predict: 0.0\n",
            "     Else (feature 38 > 0.06)\n",
            "      Predict: 1.0\n",
            "  Else (feature 22 > 68.0)\n",
            "   If (feature 5 <= 0.0)\n",
            "    If (feature 11 <= 0.0)\n",
            "     Predict: 1.0\n",
            "    Else (feature 11 > 0.0)\n",
            "     Predict: 0.0\n",
            "   Else (feature 5 > 0.0)\n",
            "    If (feature 2 in {0.0,10.0,1.0,3.0,23.0})\n",
            "     If (feature 4 <= 6.0)\n",
            "      Predict: 1.0\n",
            "     Else (feature 4 > 6.0)\n",
            "      Predict: 0.0\n",
            "    Else (feature 2 not in {0.0,10.0,1.0,3.0,23.0})\n",
            "     If (feature 0 <= 338.0)\n",
            "      Predict: 1.0\n",
            "     Else (feature 0 > 338.0)\n",
            "      Predict: 0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRobb5_gTofc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e64ef3d8-804d-434a-ef0c-9551b7085a53"
      },
      "source": [
        "print (\"Service 0 is {}\".format(services[0]))\n",
        "print (\"Service 52 is {}\".format(services[52]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Service 0 is http\n",
            "Service 52 is netbios_dgm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMmF-bx_Tv_n"
      },
      "source": [
        "## Building a minimal model using the three main splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwbeL2iOR3_5"
      },
      "source": [
        "def create_labeled_point_minimal(line_split):\n",
        "    # leave_out = [41]\n",
        "    clean_line_split = line_split[3:4] + line_split[5:6] + line_split[22:23]\n",
        "    \n",
        "    # convert flag to numeric categorical variable\n",
        "    try:\n",
        "        clean_line_split[0] = flags.index(clean_line_split[0])\n",
        "    except:\n",
        "        clean_line_split[0] = len(flags)\n",
        "    \n",
        "    # convert label to binary label\n",
        "    attack = 1.0\n",
        "    if line_split[41]=='normal.':\n",
        "        attack = 0.0\n",
        "        \n",
        "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96z_FOtER9EB"
      },
      "source": [
        "training_data_minimal = csv_data.map(create_labeled_point_minimal)\n",
        "test_data_minimal = test_csv_data.map(create_labeled_point_minimal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_BlbS20R_nm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e8870a0-12fe-4bb7-bc18-86106dfd3a81"
      },
      "source": [
        "# Build the model\n",
        "t0 = time()\n",
        "tree_model_minimal = DecisionTree.trainClassifier(training_data_minimal, numClasses=2, \n",
        "                                          categoricalFeaturesInfo={0: len(flags)},\n",
        "                                          impurity='gini', maxDepth=3, maxBins=32)\n",
        "tt = time() - t0\n",
        "\n",
        "print (\"Classifier trained in \",round(tt,3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier trained in  8.042  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTfYyvTtSB9U"
      },
      "source": [
        "predictions_minimal = tree_model_minimal.predict(test_data_minimal.map(lambda p: p.features))\n",
        "labels_and_preds_minimal = test_data_minimal.map(lambda p: p.label).zip(predictions_minimal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GHToeAuSF3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5ffa2d2-8a75-4490-f184-116a0a5eb183"
      },
      "source": [
        "t0 = time()\n",
        "test_accuracy = labels_and_preds_minimal.filter(lambda x: x[0] == x[1]).count() / float(test_data_minimal.count())\n",
        "tt = time() - t0\n",
        "\n",
        "print (\"Prediction made in \",round(tt,3),\" seconds. Test accuracy is \",round(test_accuracy,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction made in  8.889  seconds. Test accuracy is  0.9143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGpde4rcSJBh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}